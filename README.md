Here is a detailed `README.md` for your ResNet-based Crowd Counting project:

---

````markdown
# ğŸ§  ResNet-Based Crowd Counting Model

This project implements a high-accuracy crowd counting pipeline using a fine-tuned `ResNet50` backbone for **regression-based person count estimation** from images. It was designed for the **Kaggle Olympiad Crowd Density Prediction Challenge**, but the architecture is flexible and works on any crowd image dataset with image-wise count annotations.

---

## ğŸ“Œ Features

- ğŸ” **Regression-based crowd counting** using ResNet50
- ğŸ§ª **Test-time augmentation (TTA)** for more stable predictions
- ğŸ§  **Transfer learning** with selective fine-tuning
- ğŸ”„ **Stochastic Weight Averaging (SWA)** to stabilize training
- ğŸ“ˆ **Learning rate warmup & scheduling**
- ğŸ§¹ **Data preprocessing and augmentation**
- âœ… Compatible with **Google Colab**, **PyTorch**, and **Kaggle Datasets**

---

## ğŸ§¬ Project Structure

```bash
ğŸ“ crowd-counter-resnet/
â”œâ”€â”€ main.py      # ğŸ“Œ Full training + inference code
â”œâ”€â”€ submission_highacc.csv      # âœ… Final output (submission format)
â”œâ”€â”€ training_data.csv           # ğŸ· Image ID + person count
â”œâ”€â”€ test/                       # ğŸ” Test images
â”œâ”€â”€ output_train/train/         # ğŸ§  Training/Validation images
â””â”€â”€ README.md                   # ğŸ“– This file
````

---

## ğŸ”§ Setup Instructions

### 1. Environment

Install the required packages:

```bash
pip install torch torchvision transformers pandas tqdm
```

If running on Google Colab:

```python
from google.colab import drive
drive.mount('/content/drive')
```

---

### 2. Folder Structure Expected

```
ğŸ“ /content/drive/MyDrive/kaggle-olympiad-crowd-density-prediction/
â”œâ”€â”€ training_data.csv                  # Columns: id,count
â”œâ”€â”€ output_train/train/seq_000001.jpg # Images for training
â”œâ”€â”€ test/test/seq_01501.jpg           # Images for testing
```

---

### 3. Run Training

Edit the paths in `main.py` and execute:

```bash
python main.py
```

This will:

* Train the model with **ResNet50 + dropout**
* Apply **data augmentations** like flip, color jitter, rotation
* Save the best model as `resnet50_regressor_best.pth`

---

### 4. Run Inference

The same script performs inference at the end using:

* **Test-Time Augmentation (TTA)**: predicts on original and flipped images
* Aggregates predictions and saves results in:

  ```bash
  submission_highacc.csv
  ```

---

## ğŸ“Š Model Architecture

```text
ResNet50 (pretrained on ImageNet)
â””â”€â”€ Remove FC layer
â””â”€â”€ AdaptiveAvgPool2d
â””â”€â”€ Flatten
â””â”€â”€ Linear(2048 â†’ 256) + ReLU + Dropout(0.3)
â””â”€â”€ Linear(256 â†’ 1)  â†’ outputs person count (float)
```

* Only `layer4` and custom regressor are trained (rest frozen)

---

## ğŸ§ª Evaluation Metric

We use **Root Mean Squared Error (RMSE)**:

$$
\text{RMSE} = \sqrt{ \frac{1}{N} \sum_{i=1}^{N} (\hat{y}_i - y_i)^2 }
$$

During training, both `Train RMSE` and `Validation RMSE` are monitored.

---

## ğŸ“ˆ Training Tricks Used

| Trick                 | Description                                           |
| --------------------- | ----------------------------------------------------- |
| ğŸ” **TTA**            | Flip images at test time and average predictions      |
| ğŸ§  **SWA**            | Averages weights from the last few epochs             |
| ğŸ”„ **LR Scheduler**   | Linear warmup followed by gradual decay               |
| ğŸ¨ **Augmentation**   | Resize, flip, color jitter, rotate                    |
| â›” **Freezing layers** | ResNet frozen except for last block (layer4) and head |

---

## ğŸ“¤ Sample Submission Format

```csv
id,count
1501,38
1502,45
1503,51
...
```

---

## ğŸ”‘ Possible Improvements

* Use **CSRNet** or **SANet** with density map supervision
* Switch to **EfficientNet** for better feature extraction
* Integrate **multi-scale patches** to boost detail recognition
* Apply **self-supervised pretraining** for better generalization

---

## ğŸ§  Author & Credits

**ğŸ‘¤ Soham Penshanwar**
Final Year AI & Data Science | K.K. Wagh Institute of Engineering

This project was inspired by real-world challenges in analyzing CCTV footfall, safety monitoring, and public infrastructure planning.

---

## ğŸ“œ License

This code has been released under the Apache 2.0 open source license.

```